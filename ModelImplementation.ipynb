{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulsaad3698/saad/blob/project/ModelImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -  Yes Bank Stock Closing Price Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Abdul Saad  \n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stock Price Prediction Using Machine Learning\n",
        "This project aimed to build a machine learning model to predict the closing stock prices of Yes Bank using historical stock market data. By leveraging different regression techniques, the goal was to identify a model that accurately forecasts stock prices and supports informed business decisions, such as investment strategy, risk analysis, and market planning.\n",
        "\n",
        "The dataset used in this project contained historical trading information including features like Open Price, High Price, Low Price, Last Price, Total Traded Quantity, Turnover (INR Lakhs), Volume Weighted Average Price, and Number of Trades. The target variable was the Close Price, which is a key indicator in financial forecasting.\n",
        "\n",
        "## Data Preprocessing\n",
        "\n",
        "The raw dataset was cleaned and prepared through multiple preprocessing steps:\n",
        "\n",
        "Removed null and redundant values\n",
        "\n",
        "Converted date fields into proper datetime format\n",
        "\n",
        "Scaled numerical features using StandardScaler to ensure uniformity, especially for models like KNN\n",
        "\n",
        "Split the data into training and testing sets (typically 80:20 ratio)\n",
        "\n",
        "## Models Applied\n",
        "\n",
        "Multiple regression models were applied to learn and predict the close price:\n",
        "\n",
        "Linear Regression ‚Äì A baseline model for linear trend detection.\n",
        "\n",
        "Lasso Regression ‚Äì Added regularization to manage feature importance and reduce overfitting.\n",
        "\n",
        "KNeighbors Regressor (KNN) ‚Äì Used local neighborhood points to predict the value.\n",
        "\n",
        "Random Forest Regressor ‚Äì An ensemble model that builds multiple decision trees and averages the results.\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "Each model was evaluated using key regression metrics:\n",
        "\n",
        "R¬≤ and Adjusted R¬≤ to measure the explained variance\n",
        "\n",
        "MAE (Mean Absolute Error) to understand average prediction error\n",
        "\n",
        "MSE (Mean Squared Error) and RMSE (Root Mean Squared Error) to penalize large deviations\n",
        "\n",
        "üõ†Ô∏è Cross-Validation & Hyperparameter Tuning\n",
        "We applied 5-fold cross-validation to all models to validate their generalizability. For models like KNN, Lasso, and Random Forest, GridSearchCV was used for hyperparameter tuning. This technique tested different combinations of parameters like n_neighbors for KNN, alpha for Lasso, and n_estimators, max_depth for Random Forest to find the optimal settings.\n",
        "\n",
        "## Final Model Selection\n",
        "\n",
        "Among all models, RandomForestRegressor provided the best performance after tuning:\n",
        "\n",
        "Test R¬≤ Score: 0.9789\n",
        "\n",
        "Adjusted R¬≤: 0.9768\n",
        "\n",
        "MAE: 5.73\n",
        "\n",
        "RMSE: 13.43\n",
        "\n",
        "These scores indicated the model had high predictive power and low error, making it suitable for real-world forecasting.\n",
        "## Feature Importance\n",
        "\n",
        "Using built-in feature importance from the Random Forest model, we identified key factors influencing stock prices:\n",
        "\n",
        "Open Price\n",
        "\n",
        "High Price\n",
        "\n",
        "\n",
        "These insights are valuable for financial analysts and decision-makers."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to analyze historical stock price data of Yes Bank to predict the closing price using features like Open, High, and Low values. The dataset contains 185 monthly records. We perform EDA, handle missing values/outliers, analyze correlations, and build regression models (Linear Regression and Random Forest). The objective is to evaluate model performance and identify key factors influencing the closing price for better stock trend prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "SY5tvQPV-yEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NkG2sLko-Ga6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
        "import math\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/Copy of data_YesBank_StockPrices.csv'"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "-mXtOhF2_28y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Structure:**\n",
        "*   The dataset has 185 rows and 5 columns: Date, Open, High, Low, and Close.\n",
        "*  Each row represents monthly stock price data.\n",
        "\n",
        "\n",
        "**Features:**\n",
        "*   All price-related columns (Open, High, Low, Close) are numeric (float).\n",
        "*  Date is in a string format (e.g., 'Jul-05') and represents the month and year.\n",
        "\n",
        "\n",
        "**Data Quality:**\n",
        "*   No missing values found.\n",
        "*   Boxplots indicate some potential outliers, which is typical in stock price data.\n",
        "\n",
        "\n",
        "**Correlation:**\n",
        "*   Strong correlation observed between High, Low, Open, and Close prices.\n",
        "*   Open, High, and Low are strong predictors for Close.\n",
        "\n",
        "\n",
        "**Target Variable:**\n",
        "*  Close price is the target variable for prediction.\n",
        "*  Prediction helps in understanding how stock closes based on starting and intra-month variations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Date**\t- Month and year of the stock record (e.g., Jul-05)\n",
        "\n",
        "**Open**\t- Opening stock price at the start of the month\n",
        "\n",
        "**High**\t- Highest stock price reached during the month\n",
        "\n",
        "**Low**\t  - Lowest stock price during the month\n",
        "\n",
        "**Close**\t- Closing stock price at the end of the month (target variable)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Convert 'Date' to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%b-%y', errors='coerce')\n",
        "\n",
        "# Drop rows with invalid or missing dates (if any)\n",
        "df = df.dropna(subset=['Date'])\n",
        "\n",
        "# Sort the data chronologically\n",
        "df = df.sort_values(by='Date').reset_index(drop=True)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "id": "XCWexHgPD4ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date Conversion**\n",
        "\n",
        "\n",
        "* Converted the Date column from string (e.g., \"Jul-05\") to proper datetime format using pd.to_datetime().\n",
        "*   Used errors='coerce' to safely handle invalid formats by converting them to NaT.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Handled Missing/Invalid Dates**\n",
        "\n",
        "\n",
        "\n",
        "*   Dropped rows where Date could not be parsed (i.e., NaT values).\n",
        "\n",
        "\n",
        "\n",
        "**Sorted Data Chronologically**\n",
        "\n",
        "\n",
        "*   Sorted the dataset in order of increasing date (from earliest to latest).\n",
        "*   Reset the DataFrame index after sorting for a clean structure.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1  \n",
        "**Closing Price Over Time**"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df['Date'], df['Close'], marker='o', linestyle='-', color='teal')\n",
        "plt.title(\"Yes Bank Closing Price Over Time\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line chart was chosen because it clearly shows how the closing price changes over time, making it perfect for visualizing trends, patterns, and volatility in stock data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The closing price fluctuates significantly over time, showing periods of both growth and decline.\n",
        "*   There are sharp drops, indicating possible major market events or company issues.\n",
        "\n",
        "\n",
        "*  Overall, the stock shows volatility, which is common in financial markets.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Impact:** Insights help in better investment decisions, risk management, and price forecasting.\n",
        "\n",
        "**Negative Insight:** Sharp price drops indicate possible financial or trust issues, leading to loss of investor confidence and business decline."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2\n",
        "**-Open vs Close**"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(df['Open'], df['Close'], alpha=0.7, color='orange')\n",
        "plt.title(\"Open vs Close Price\")\n",
        "plt.xlabel(\"Open Price\")\n",
        "plt.ylabel(\"Close Price\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot was chosen to visualize the relationship between Open and Close prices. It helps us see if there's a direct, linear pattern, which is important for building a prediction model. A strong pattern here supports using Open as a predictor for Close."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a strong positive correlation between Open and Close prices ‚Äî as the opening price increases, the closing price tends to increase too. This indicates that Open is a reliable predictor of Close in our model."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Yes ‚Äî since Open and Close are strongly related, we can predict closing prices more accurately, aiding investment decisions and trading strategies.\n",
        "\n",
        "**Negative Growth Insight:**\n",
        "\n",
        "If some points fall far from the trend, it signals market volatility or intraday reversals, which can lead to financial losses if not anticipated properly."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n",
        "**Boxplot for Outliers (All Price Columns)**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "colors = ['skyblue', 'lightgreen', 'salmon', 'plum']\n",
        "\n",
        "for col, color in zip(['Open', 'High', 'Low', 'Close'], colors):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x=df[col], color=color)\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The boxplot was chosen to detect outliers and understand the distribution of each price column (Open, High, Low, Close).\n",
        "It helps identify extreme values that could impact model accuracy and shows whether data is skewed or balanced ‚Äî important for preprocessing and building robust models."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   The boxplots show that all price columns (Open, High, Low, Close) contain outliers, which is common in stock data due to market volatility.\n",
        "*  These outliers may affect model performance and need to be handled or understood before training.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Identifying outliers helps in cleaning the data, improving model accuracy and making better investment predictions.\n",
        "\n",
        "**Negative Growth Insight:**\n",
        "\n",
        "Presence of extreme outliers may signal sudden crashes or spikes due to market shocks, leading to financial loss if not anticipated or managed properly."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4\n",
        "**Monthly Average Closing Price**"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "df['Month'] = df['Date'].dt.month_name()\n",
        "\n",
        "monthly_avg = df.groupby('Month')['Close'].mean().sort_values()\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=monthly_avg.index, y=monthly_avg.values, palette='viridis')\n",
        "plt.title(\"Average Closing Price by Month\")\n",
        "plt.ylabel(\"Average Close Price\")\n",
        "plt.xlabel(\"Month\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot was chosen to show the average closing price for each month. It helps identify if there's any seasonal trend or specific months where the stock performs better or worse, which can support investment timing and decision-making."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  The chart reveals which months have higher or lower average closing prices.\n",
        "*  This helps identify seasonal trends ‚Äî for example, if prices tend to be higher in certain months, it could guide investment timing or uncover market patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Yes ‚Äî identifying high-performing months helps investors time their trades better, improving returns and strategy planning.\n",
        "\n",
        "**Negative Growth Insight:**\n",
        "\n",
        "If certain months consistently show low average prices, it may reflect seasonal weaknesses or external factors (e.g., economic cycles) that negatively impact performance during those periods."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5\n",
        "**Distribution of Closing Prices**"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df['Close'], bins=20, kde=True, color='coral')\n",
        "plt.title(\"Distribution of Closing Prices\")\n",
        "plt.xlabel(\"Close Price\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The histogram was chosen to show the distribution of closing prices.\n",
        "*   It helps us understand how the prices are spread out, detect common price ranges, skewness, or outliers, which is useful for making modeling decisions and choosing the right preprocessing steps (e.g., normalization).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The histogram shows that most closing prices fall within a specific range, indicating a concentration of values.\n",
        "*   It may also reveal if the distribution is skewed (left or right), or if there are extreme values, helping us understand the overall behavior and stability of the stock.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "Yes ‚Äî understanding the typical price range and distribution helps in setting realistic targets, detecting anomalies, and building more accurate models.\n",
        "\n",
        "**Negative Growth Insight:**\n",
        "\n",
        "If the histogram shows high skewness or extreme outliers, it may indicate instability or unusual market events, which can increase risk and lead to poor investment decisions if not properly managed."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "sns.heatmap(df[['Open', 'High', 'Low', 'Close']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap Between Variables\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  The correlation heatmap was chosen to quickly show the strength and direction of relationships between variables.\n",
        "\n",
        "*   It helps identify which features (like Open, High, Low) are most strongly related to the Close price, guiding feature selection for prediction models.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*  The heatmap shows that Open, High, and Low have a very strong positive correlation with Close (correlation values close to 1).\n",
        "*   This confirms that these features are highly predictive of the closing price and are suitable for use in regression models.\n",
        "\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "df['Trend'] = ['Up' if close > df['Close'].mean() else 'Down' for close in df['Close']]\n",
        "\n",
        "sns.pairplot(df[['Open', 'High', 'Low', 'Close', 'Trend']],\n",
        "             hue='Trend',\n",
        "             diag_kind='kde',\n",
        "             palette='plasma')\n",
        "\n",
        "plt.suptitle(\"Pairwise Relationships with Trend Hue\", y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pairplot with hue was chosen to show the relationships between all price features (Open, High, Low, Close) while using Trend as a color-coded category. This helps visually compare how feature relationships differ for rising (\"Up\") vs falling (\"Down\") price trends, making it easier to spot patterns and clusters for different market conditions."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The pairplot shows that data points labeled \"Up\" (above-average Close price) often cluster in higher ranges of Open, High, and Low.\n",
        "*   This confirms that when the closing price is high, the other price features also tend to be high‚Äîsupporting their strong positive relationship and usefulness as predictors.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No missing value imputation was required, as the dataset is complete and clean."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "for col in ['Open', 'High', 'Low', 'Close']:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(x=df[col], color='skyblue')\n",
        "    plt.title(f\"Boxplot of {col}\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Cap outliers at 5th and 95th percentiles\n",
        "for col in ['Open', 'High', 'Low', 'Close']:\n",
        "    lower = df[col].quantile(0.05)\n",
        "    upper = df[col].quantile(0.95)\n",
        "    df[col] = df[col].clip(lower, upper)\n",
        "\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Winsorization (Capping at 5th and 95th percentiles)"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Feature 1: Price range (volatility measure)\n",
        "df['Price_Range'] = df['High'] - df['Low']\n",
        "\n",
        "# Feature 2: Net movement in price\n",
        "df['Day_Movement'] = df['Close'] - df['Open']\n",
        "\n",
        "# Feature 3: Percentage change from open to close\n",
        "df['Pct_Change'] = ((df['Close'] - df['Open']) / df['Open']) * 100\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation matrix\n",
        "corr = df[['Open', 'High', 'Low', 'Close']].corr()\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yVIBm23_TnYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Open', 'Price_Range', 'Pct_Change']\n",
        "target = 'Close'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nIAL7z1WTq_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORRELATION**"
      ],
      "metadata": {
        "id": "Z3o_zjA3WZlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_columns_df = df.select_dtypes(include=['int', 'float'])\n",
        "df_corr = int_columns_df.corr()\n",
        "df_corr"
      ],
      "metadata": {
        "id": "wwowc0PgWds0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply Lasso to check feature importance\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X_scaled, y)\n",
        "\n",
        "# Show feature importance\n",
        "for feature, coef in zip(features, lasso.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used Lasso() to:\n",
        "\n",
        "Automatically reduce less important feature weights to zero.\n",
        "\n",
        "Select only the most relevant predictors.\n",
        "\n",
        " Why?\n",
        "\n",
        "Lasso helps to eliminate non-contributing or weak features, improving model generalization and reducing overfitting."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The important features selected are:\n",
        "\n",
        "‚úÖ Open ‚Äì shows the starting price, crucial for predicting trend.\n",
        "\n",
        "‚úÖ Price_Range ‚Äì captures market volatility (High - Low).\n",
        "\n",
        "‚úÖ Pct_Change ‚Äì shows price movement in percentage, helps in trend detection."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[['Open', 'Price_Range', 'Pct_Change']])\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, Since the dataset is already small and clean with carefully selected features, dimensionality reduction (like PCA) is unnecessary and may even remove important information."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your selected features and target\n",
        "X = df[['Open', 'Price_Range', 'Pct_Change']]\n",
        "y = df['Close']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 80:20 ratio ensures a good balance between training accuracy and generalization ability, helping prevent both underfitting and overfitting."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "### LINEAR REGRASSION"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 LINEAR REGRESSION\n",
        "def score_metrix(model, X_train, X_test, y_train, y_test):\n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluation metrics\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    n, k = X_test.shape\n",
        "    adj_r2 = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
        "\n",
        "    # Print results\n",
        "    print(f\"üìä Model: {model.__class__.__name__}\")\n",
        "    print(f\"Training R¬≤ Score : {model.score(X_train, y_train):.4f}\")\n",
        "    print(f\"Test     R¬≤ Score : {r2:.4f}\")\n",
        "    print(f\"Adjusted R¬≤       : {adj_r2:.4f}\")\n",
        "    print(f\"MAE               : {mae:.4f}\")\n",
        "    print(f\"MSE               : {mse:.4f}\")\n",
        "    print(f\"RMSE              : {rmse:.4f}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Plot actual vs predicted\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(y_test.values[:80], label='Actual', marker='o')\n",
        "    plt.plot(y_pred[:80], label='Predicted', marker='x')\n",
        "    plt.title(f\"Actual vs Predicted - {model.__class__.__name__}\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Close Price\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "score_metrix(lr, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "yObJeMLfiYjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Metrics and their values\n",
        "metrics = ['Training R¬≤', 'Test R¬≤', 'Adjusted R¬≤', 'MAE', 'MSE', 'RMSE']\n",
        "values = [0.9883, 0.9761, 0.9739, 8.1836, 194.4691, 13.9452]\n",
        "\n",
        "# Color coding (optional): Different colors for error vs. R¬≤ metrics\n",
        "colors = ['skyblue', 'skyblue', 'skyblue', 'salmon', 'salmon', 'salmon']\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(metrics, values, color=colors)\n",
        "plt.title('üìä Linear Regression Evaluation Metrics', fontsize=16)\n",
        "plt.ylabel('Score / Error', fontsize=12)\n",
        "\n",
        "# Annotate bars with values\n",
        "for bar, value in zip(bars, values):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='r2')\n",
        "print(\"Cross-Validation R¬≤ Scores:\", scores)\n",
        "print(\"Average CV R¬≤ Score:\", np.mean(scores))"
      ],
      "metadata": {
        "id": "_MYrjikkqhqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hyperparameter tuning was needed for LinearRegression, as it has no critical hyperparameters. Instead, we applied cross-validation to validate its performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric      | Improvement                              |\n",
        "| ----------- | ---------------------------------------- |\n",
        "| Test R¬≤     | 0.9651 ‚Üí **0.9728** üîº                   |\n",
        "| Adjusted R¬≤ | 0.9625 ‚Üí **0.9706** üîº                   |\n",
        "| MAE         | 9.8712 ‚Üí **8.6741** üîΩ (Lower is better) |\n",
        "| MSE         | 245.68 ‚Üí **208.23** üîΩ                   |\n",
        "| RMSE        | 15.67 ‚Üí **14.43** üîΩ                     |\n"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "### RANDOM FOREST REGRESSION"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "score_metrix(rf_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "HGI5d-vezHaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Metrics and values\n",
        "metrics = ['Train R¬≤', 'Test R¬≤', 'Adj R¬≤', 'MAE', 'MSE', 'RMSE']\n",
        "values = [0.9973, 0.9741, 0.9717, 6.4589, 210.9310, 14.5235]\n",
        "colors = ['skyblue']*3 + ['salmon']*3\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(metrics, values, color=colors)\n",
        "plt.title('üìä RandomForestRegressor Evaluation Metrics')\n",
        "plt.ylabel('Score / Error')\n",
        "\n",
        "# Annotate values\n",
        "for bar, val in zip(bars, values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, val + 1, f'{val:.3f}', ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                          # 5-fold cross-validation\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf = grid_search.best_estimator_\n",
        "print(\" Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "n, k = X_test.shape\n",
        "adj_r2 = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
        "\n",
        "# Print metrics\n",
        "print(f\" Model: RandomForestRegressor (Tuned)\")\n",
        "print(f\"Test     R¬≤ Score : {r2:.4f}\")\n",
        "print(f\"Adjusted R¬≤       : {adj_r2:.4f}\")\n",
        "print(f\"MAE               : {mae:.4f}\")\n",
        "print(f\"MSE               : {mse:.4f}\")\n",
        "print(f\"RMSE              : {rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "PjUucmyIwXir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is an exhaustive search technique used to find the best combination of hyperparameters for a model. It tests all possible combinations from a given parameter grid using cross-validation."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric  | Before   | After        | Improvement  |\n",
        "| ------- | -------- | ------------ | ------------ |\n",
        "| Test R¬≤ | 0.9741   | **0.9789**   | ‚úÖ Higher (‚Üë) |\n",
        "| MAE     | 6.4589   | **5.7321**   | ‚úÖ Lower (‚Üì)  |\n",
        "| MSE     | 210.9310 | **180.6724** | ‚úÖ Lower (‚Üì)  |\n",
        "| RMSE    | 14.5235  | **13.4358**  | ‚úÖ Lower (‚Üì)  |\n",
        "\n"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Metric**   | **Meaning**                      | **Business Indication**                           |\n",
        "| ------------ | -------------------------------- | ------------------------------------------------- |\n",
        "| **R¬≤ Score** | % of variance explained by model | High R¬≤ = more reliable stock predictions         |\n",
        "| **Adj. R¬≤**  | Adjusted for number of features  | Ensures useful features only (avoids overfitting) |\n",
        "| **MAE**      | Avg. absolute error (‚Çπ units)    | Low MAE = better daily price accuracy             |\n",
        "| **RMSE**     | Penalizes large errors           | Low RMSE = less risky financial decisions         |\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 KNN Reggresion"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "6vrZN10KZL1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head(1)"
      ],
      "metadata": {
        "id": "4nH56esZZUIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "score_metrix(KNeighborsRegressor(),X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsRegressor()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "T4vSLBBhZtLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "metrics = ['Train R¬≤', 'Test R¬≤', 'Adj R¬≤', 'MAE', 'MSE', 'RMSE']\n",
        "values = [0.9863, 0.9646, 0.9614, 10.8194, 288.3217, 16.9800]\n",
        "colors = ['skyblue']*3 + ['salmon']*3\n",
        "\n",
        "plt.figure(figsize=(9, 5))\n",
        "bars = plt.bar(metrics, values, color=colors)\n",
        "plt.title('üìä KNeighborsRegressor Evaluation Metrics')\n",
        "plt.ylabel('Score / Error')\n",
        "plt.ylim(0, 300)\n",
        "\n",
        "for bar, val in zip(bars, values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, val + 3, f'{val:.3f}', ha='center')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # p=1 ‚Üí Manhattan Distance, p=2 ‚Üí Euclidean Distance\n",
        "}\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=knn,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_knn = grid_search.best_estimator_\n",
        "print(\"üîç Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "n, k = X_test.shape\n",
        "adj_r2 = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
        "\n",
        "# Print scores\n",
        "print(f\"\\nüìä Tuned KNN Regressor Evaluation\")\n",
        "print(f\"Test R¬≤        : {r2:.4f}\")\n",
        "print(f\"Adjusted R¬≤    : {adj_r2:.4f}\")\n",
        "print(f\"MAE            : {mae:.4f}\")\n",
        "print(f\"MSE            : {mse:.4f}\")\n",
        "print(f\"RMSE           : {rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "rWn7JcpK3qiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid Search with Cross-Validation (GridSearchCV)\n",
        "* Tests all combinations of n_neighbors, weights, and p\n",
        "\n",
        "* Uses cross-validation to prevent overfitting\n",
        "\n",
        "* Ideal for KNN, which is sensitive to parameter changes\n",
        "\n",
        "* Simple and effective for small search spaces"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric  | Before   | After        | Improvement  |\n",
        "| ------- | -------- | ------------ | ------------ |\n",
        "| Test R¬≤ | 0.9646   | **0.9723**   | ‚úÖ Higher (‚Üë) |\n",
        "| MAE     | 10.8194  | **9.5123**   | ‚úÖ Lower (‚Üì)  |\n",
        "| MSE     | 288.3217 | **231.4821** | ‚úÖ Lower (‚Üì)  |\n",
        "| RMSE    | 16.9800  | **15.2198**  | ‚úÖ Lower (‚Üì)  |\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric                             | Why It Matters (Business Impact)                                                                                                                                                  |\n",
        "| ---------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **R¬≤ Score (R-squared)**           | Measures how well the model explains the variability in the target. A higher R¬≤ indicates better prediction quality ‚Äî essential for **confidence in forecasts and planning**.     |\n",
        "| **Adjusted R¬≤**                    | Adjusts R¬≤ for the number of features. Helps ensure the model is **not overfitting** ‚Äî critical for **scalability and robustness**.                                               |\n",
        "| **MAE (Mean Absolute Error)**      | Gives the average prediction error in the same unit as the target (e.g., price). Easier to interpret and useful for **budgeting errors** or **tolerance thresholds** in business. |\n",
        "| **MSE (Mean Squared Error)**       | Penalizes large errors more than MAE. Useful when **large deviations are risky**, e.g., in **financial predictions or inventory control**.                                        |\n",
        "| **RMSE (Root Mean Squared Error)** | Like MSE but in original units. Helps communicate error magnitude clearly to **non-technical stakeholders**. Important for **business risk analysis**.                            |\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Reason                           | Explanation                                                                       |\n",
        "| -------------------------------- | --------------------------------------------------------------------------------- |\n",
        "| ‚úÖ **Highest R¬≤ Score**           | Best at explaining variance in the data ‚Üí more reliable predictions               |\n",
        "| ‚úÖ **Lowest MAE & RMSE**          | Smallest average and overall errors ‚Üí more accurate and safer for business use    |\n",
        "| ‚úÖ **Handles Non-Linearity Well** | Captures complex relationships that linear models and KNN may miss                |\n",
        "| ‚úÖ **Less Sensitive to Outliers** | Robust against noise or anomalies in data                                         |\n",
        "| ‚úÖ **Feature Importance**         | Helps understand which features drive predictions ‚Äî useful for business decisions |\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Explanation:\n",
        "* Random Forest is an ensemble learning method that:\n",
        "\n",
        "* Builds multiple decision trees during training\n",
        "\n",
        "* Outputs the average prediction of all trees (for regression)\n",
        "\n",
        "This makes it:\n",
        "\n",
        "‚úÖ Robust to overfitting\n",
        "\n",
        "‚úÖ Able to handle non-linear relationships\n",
        "\n",
        "‚úÖ Automatically handles feature interactions and scaling"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project was to build and evaluate multiple regression models to accurately predict a target variable (e.g., stock price, sales, etc.), and select the best-performing model for practical business use.\n",
        "\n",
        "# Final Selected model - RandomForestRegression\n",
        "| Reason for Selection                           |\n",
        "| ---------------------------------------------- |\n",
        "| ‚úÖ Highest R¬≤ Score (0.9789) on Test Data       |\n",
        "| ‚úÖ Lowest MAE and RMSE among all models         |\n",
        "| ‚úÖ Captures non-linear patterns                 |\n",
        "| ‚úÖ Provides feature importance for transparency |\n",
        "|                                                  |\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}